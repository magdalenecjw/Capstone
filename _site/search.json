[
  {
    "objectID": "Analysis/Setup/DataPrep.html",
    "href": "Analysis/Setup/DataPrep.html",
    "title": "Data Preparation",
    "section": "",
    "text": "Getting Started\nThe code chunk below uses p_load() function of pacman package to check if the required packages have been installed on the computer. If they are, the packages will be launched.\nThe packages used are: - arrow package to read and write Parquet files, which is the format that our source data is in. - fs package for smoother file handling. - tidyverse package for aspatial data wrangling. - lubridate package to handle date and time data. - data.table package for fast aggregation of large datasets.\n\n\nCode\npacman::p_load(arrow, fs, tidyverse, lubridate, data.table)\n\n\nThe dataset is provided by Grab over 10 separate files (in Apache Parquet file format), with each trajectory ID (primary identifier of each trip) found in multiple files. There is a need to join the 10 files before performing any further data wrangling. In the code chunk below, read_parquet() from arrow package is used to read the Parquet files. As there are 10 such files, a loop function is used to load each Parquet file within the file directory and stored into a list, which is finally then merged using bind_rows() function from dplyr package. Lastly, as the pingtimestamp field is in integer format, it is converted into date-time format using as_datetime() function of lubridate package\n\n\nCode\n# List Parquet files in the directory\nparquet_files &lt;- dir_ls(\"../data/\", regexp = \"\\\\.parquet$\")\n\n# Initialize an empty list to store dataframes\ndfs &lt;- list()\n\n# Loop through each Parquet file, read it, and store in the list\nfor (file_path in parquet_files) {\n  df &lt;- read_parquet(file_path)\n  dfs &lt;- append(dfs, list(df))\n}\n\n# Combine individual dataframes into one dataframe\ngrab &lt;- bind_rows(dfs) %&gt;%\n  # Convert pingtimestamp column to date-time format\n  mutate(pingtimestamp = as_datetime(pingtimestamp))\n\n# Remove objects that will no longer be used\nrm(df, dfs, file_path, parquet_files)\n\n\nFor sorting a large tibble data frame efficiently in R, while dplyr package offers the arrange() function, it typically does not perform the task as quickly as setorder() function of data.table package. data.table package often offers better performance for sorting large datasets due to its efficient memory management and optimized algorithms.\n\n\nCode\n# Set tibble dataframe as data.table \n# Then sort by trajectory ID and pingtimestamp\ngrab_sorted &lt;- setorder(as.data.table(grab), trj_id, pingtimestamp)\n\n# Convert back to tibble dataframe\ngrab_sorted &lt;- as_tibble(grab_sorted)\n\n# Remove objects that will no longer be used\nrm(grab)\n\n\n\n\nData Wrangling\nThere is a need to identify the Pick-up locations. In the code chunk below, group_by() function of dplyr package is used to group the data by trajectory ID, before taking the GPS coordinates (latitude and longitude) of the earliest GPS ping timestamp using filter() and min() function.\nSimilar steps are then performed to identify the Drop-off locations. group_by() function of dplyr package is used to group the data by trajectory ID, before taking the GPS coordinates (latitude and longitude) of the latest GPS ping timestamp using filter() and max() function.\n\n\nCode\n# Identify Pick-up locations\npickup_loc &lt;- grab_sorted %&gt;%\n  group_by(trj_id) %&gt;%\n  filter(pingtimestamp == min(pingtimestamp)) %&gt;%\n  ungroup() %&gt;%\n  select(trj_id, rawlat, rawlng) %&gt;%\n  rename(pickup_lat = rawlat,\n         pickup_lng = rawlng)\n\n# Identify Drop-off locations\ndropoff_loc &lt;- grab_sorted %&gt;%\n  group_by(trj_id) %&gt;%\n  filter(pingtimestamp == max(pingtimestamp)) %&gt;%\n  ungroup() %&gt;%\n  select(trj_id, rawlat, rawlng) %&gt;%\n  rename(dropoff_lat = rawlat,\n         dropoff_lng = rawlng)\n\n# Merge both pick-up and drop-off locations into a O-D flow\ngrab_odflow &lt;- pickup_loc %&gt;%\n  left_join(dropoff_loc, by = \"trj_id\")\n\n\n\n\nMap Matching\nGiven that our dataset is based on GPS pings from drivers’ phones while in transit, the coordinates captured for any given GPS ping may not accurately reflect a point on the road network. As such, there is a need to perform “snapping” or map matching, which is the process of aligning the spatial point events with the nearest points on the network.\nMap matching will be continued in the next article."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Analysis/Setup/MapMatching.html",
    "href": "Analysis/Setup/MapMatching.html",
    "title": "Map Matching",
    "section": "",
    "text": "Getting Started\nThe code chunk below uses p_load() function of pacman package to check if the required packages have been installed on the computer. If they are, the packages will be launched.\nThe packages used are: - sf package is used for importing, managing, and processing geospatial data. - tidyverse package for aspatial data wrangling. - data.table package for fast aggregation of large datasets.\n\n\nCode\npacman::p_load(sf, tidyverse, data.table)\n\n\nIn the code chunk below, the cleaned data file is loaded into R.\n\n\nCode\n# Load rds file instead of rendering the above code chunks\ngrab_sorted &lt;- read_rds(\"../data/rds/grab_sorted.rds\")\ngrab_odflow &lt;- read_rds(\"../data/rds/grab_odflow.rds\")\n\n\n\n\nMap Matching\nGiven that our dataset is based on GPS pings from drivers’ phones while in transit, the coordinates captured for any given GPS ping may not accurately reflect a point on the road network. As such, there is a need to perform “snapping” or map matching, which is the process of aligning the spatial point events with the nearest points on the network.\nMap matching will be continued in the next article."
  },
  {
    "objectID": "Analysis/KDE/Week1.html",
    "href": "Analysis/KDE/Week1.html",
    "title": "KDE Analysis (1)",
    "section": "",
    "text": "Getting Started\nThe code chunk below uses p_load() function of pacman package to check if the required packages have been installed on the computer. If they are, the packages will be launched.\nThe packages used are:\n\nsf package is used for importing, managing, and processing geospatial data.\ntidyverse package for aspatial data wrangling.\nspatstat package to perform 1st-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\n\n\npacman::p_load(sf, sp, tidyverse, spatstat, tmap)\n\nIn the code chunk below, the cleaned data files are loaded into R.\n\n# Load base map\nmpsz = st_read(dsn = \"../data/geospatial\", \n               layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\magdalenecjw\\Capstone\\Analysis\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n# Load rds file\npickup_sf &lt;- st_as_sf(read_rds(\"../data/rds/pickup_sf.rds\"))\ndropoff_sf &lt;- st_as_sf(read_rds(\"../data/rds/dropoff_sf.rds\"))\n\n\n\nConvert Pickup and Dropoff location sf dataframes into spatstat’s ppp object format\nConvert the sf dataframe to a ppp object using as.ppp() function from the spatstat package. The result is a marked planar point pattern. To change a marked planar point pattern to just a planar point pattern, simply remove the marks associated with each point using marks(pickup_ppp) &lt;- NULL.\n\npickup_ppp &lt;- as.ppp(pickup_sf)\nmarks(pickup_ppp) &lt;- NULL\n\nplot(pickup_ppp)\n\n\n\n\n\ndropoff_ppp &lt;- as.ppp(dropoff_sf)\nmarks(dropoff_ppp) &lt;- NULL\n\nplot(dropoff_ppp)\n\n\n\n\n\n# Create border of Singapore's land area\nmpsz_border &lt;- st_cast(mpsz %&gt;%\n                         summarize(), \"POLYGON\")\n\n# Convert the resulting sf object to an owin object\nmpsz_owin &lt;- as.owin(mpsz_border)\n\nplot(mpsz_owin)\n\n\n\n\n\npickup_owin = pickup_ppp[mpsz_owin]\npickup_owin &lt;- rescale(pickup_owin, 1000, \"km\")\n\npickup_kde &lt;- density(pickup_owin, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\") \n\nplot(pickup_kde)\n\n\n\n\n\ndropoff_owin = dropoff_ppp[mpsz_owin]\ndropoff_owin &lt;- rescale(dropoff_owin, 1000, \"km\")\n\ndropoff_kde &lt;- density(dropoff_owin, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\") \n\nplot(dropoff_kde)"
  }
]